{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Build the individual models\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f1bac5bdf50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0mmodels_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/pwrai/notebook/tmp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0mct_scan_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mct_scan_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mct_scan_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iv1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_scan_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_scan_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_scan_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-5f1bac5bdf50>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(cnn, ct_scan_width, ct_scan_height, ct_scan_depth, data_path, models_path, lr, dropout_prob, epochs, batch_size, r_batch_size, n_folds)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fold_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'x_train.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'x_test.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'x_val.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/wmlce/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/wmlce/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from utils.confusion_matrix import cm as confusion_matrix \n",
    "from models.InceptionV1_3D import Inception_Inflated3d\n",
    "from models.InceptionV3_3D import Inception_v3_Inflated3d\n",
    "from tensorflow import keras\n",
    "from numpy.random import default_rng\n",
    "from tensorflow.keras import layers\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import zoom\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.MulticlassAUC import MulticlassAUC\n",
    "from os import path\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        # define some rotation angles\n",
    "        # pick angles at random\n",
    "        angle=random.randint(-30,30) \n",
    "        #angle=random.randint(1,5) \n",
    "        # rotate volume\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "     \n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def translate(volume):\n",
    "    def scipy_shift(volume):\n",
    "        # shift volume\n",
    "        shift_x = random.randint(-10,10) \n",
    "        shift_y = random.randint(-10,10) \n",
    "        shift_z = random.randint(-10,10)\n",
    "        shift=[shift_x, shift_y, shift_z]\n",
    "        volume = ndimage.shift(volume, shift)\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_shift, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    " \n",
    "    \n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    \n",
    "    k=np.random.randint(2, size=2)\n",
    "    \n",
    "    # Rotate volume\n",
    "    if k[0]==1: \n",
    "        volume = rotate(volume)\n",
    "        volume = tf.reshape(volume, [ct_scan_depth, ct_scan_width, ct_scan_height])\n",
    "    \n",
    "    # Translate volume\n",
    "    if k[1]==1:\n",
    "        volume = translate(volume)\n",
    "        volume = tf.reshape(volume, [ct_scan_depth, ct_scan_width, ct_scan_height])\n",
    "    \n",
    "     \n",
    "    volume = tf.reshape(volume, [ct_scan_depth, ct_scan_width, ct_scan_height])\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "\n",
    "def test_and_validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "\n",
    "def training(cnn,\n",
    "             ct_scan_width, \n",
    "             ct_scan_height, \n",
    "             ct_scan_depth,\n",
    "             data_path,\n",
    "             models_path,\n",
    "             lr=0.00001, \n",
    "             dropout_prob=0.0, \n",
    "             epochs=100,\n",
    "             batch_size=16,\n",
    "             r_batch_size=16,\n",
    "             n_folds=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    cnn             : cnn architecture. Use 'iv1' to use Inception-V1 or 'iv3' to use Inception-V3\n",
    "    ct_scan_width   : width of the CT scans \n",
    "    ct_scan_height  : height of the CT scans\n",
    "    ct_scan_depth   : depth (number of slices) of the CT scans\n",
    "    data_path       : path of the training/validation/test set for each fold\n",
    "    models_path     : directory where the models will be saved. If the directory does not exist it is created\n",
    "    lr              : learning rate \n",
    "    dropout_prob    : dropout value \n",
    "    epochs          : training epochs\n",
    "    batch_size      : global batch size\n",
    "    r_batch_size    : replica batch size\n",
    "    n_folds         : number of folds for k-fold cross validation (default 5-fold cross validation)   \n",
    "    \"\"\"\n",
    "    \n",
    "    # CT scans size Width x Height x Depth\n",
    "    ct_scan_width=ct_scan_width \n",
    "    ct_scan_height=ct_scan_height\n",
    "    ct_scan_depth=ct_scan_depth\n",
    "    \n",
    "    # image channels\n",
    "    num_channels = 1\n",
    "    \n",
    "    # training parameters\n",
    "    epochs=epochs               # training epochs\n",
    "    lr=lr                       # learning rate\n",
    "    batch_size = batch_size     # global batch size\n",
    "    r_batch_size = r_batch_size # replica batch size\n",
    "    dropout_prob=dropout_prob   # dropout value for the last fully connected layer\n",
    "\n",
    "    # number of folds \n",
    "    n_folds=n_folds\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    scores_acc = {'loss': np.zeros(n_folds), \n",
    "                  'categorical_accuracy': np.zeros(n_folds),\n",
    "                  'specificity': np.zeros(n_folds),\n",
    "                  'sensitivity': np.zeros(n_folds)\n",
    "                 }\n",
    "\n",
    "    scores_loss = {'loss': np.zeros(n_folds), \n",
    "                  'categorical_accuracy': np.zeros(n_folds),\n",
    "                  'specificity': np.zeros(n_folds),\n",
    "                  'sensitivity': np.zeros(n_folds)\n",
    "                  }\n",
    "\n",
    "    scores_test_lastepoch = {'loss': np.zeros(n_folds), \n",
    "                  'categorical_accuracy': np.zeros(n_folds),\n",
    "                  'specificity': np.zeros(n_folds),\n",
    "                  'sensitivity': np.zeros(n_folds)\n",
    "                }\n",
    "\n",
    "    f=0\n",
    "\n",
    "    for i in range(n_folds): \n",
    "\n",
    "        if True:\n",
    "            models_path=path.join(models_path, \"fold_\"+str(i+1) + path.sep)\n",
    "            Path(models_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "            # load preprocessed CLEAN-CC-CCII data for a given fold\n",
    "            data_path=path.join(data_path, \"fold_\"+str(i+1) + path.sep)\n",
    "\n",
    "            x_train = np.load(data_path+'x_train.npy')\n",
    "            x_test = np.load(data_path+'x_test.npy')\n",
    "            x_val = np.load(data_path+'x_val.npy')\n",
    "            y_train = np.load(data_path+'y_train.npy')\n",
    "            y_test = np.load(data_path+'y_test.npy')\n",
    "            y_val = np.load(data_path+'y_val.npy')\n",
    "\n",
    "\n",
    "            x_train.squeeze()\n",
    "            x_test.squeeze()\n",
    "            x_val.squeeze()\n",
    "\n",
    "            x_train = np.swapaxes( x_train, 1, -1); x_train = np.swapaxes( x_train, -2, -1)\n",
    "            x_test = np.swapaxes( x_test, 1, -1); x_test = np.swapaxes( x_test, -2, -1)\n",
    "            x_val = np.swapaxes( x_val, 1, -1); x_val = np.swapaxes( x_val, -2, -1)\n",
    "\n",
    "\n",
    "            print('Number of samples ' )\n",
    "            print('Training set: %d chest CT scans' % (x_train.shape[0]))\n",
    "            print('Test set: %d chest CT scans' % (x_test.shape[0]))\n",
    "            print('Validation set: %d chest CT scans' % (x_val.shape[0]))\n",
    "\n",
    "            \n",
    "            \n",
    "            model = None\n",
    "            \n",
    "            if cnn=='iv1':\n",
    "                print(\"Using 3D Inception-V1\")\n",
    "                model = Inception_Inflated3d(include_top=False, \n",
    "                                                      input_shape=(ct_scan_depth, ct_scan_width, ct_scan_height, num_channels),\n",
    "                                                      dropout_prob=dropout_prob, classes=3)\n",
    "            elif cnn=='iv3':\n",
    "                print(\"Using 3D Inception-V3\")\n",
    "                model = Inception_v3_Inflated3d(include_top=False, \n",
    "                                                  input_shape=(ct_scan_depth, ct_scan_width, ct_scan_height, num_channels),\n",
    "                                                  dropout_prob=dropout_prob, classes=3)\n",
    "            else:\n",
    "                print(\"Please use 'iv1 for Inception-V1 or 'iv3' for Inception-V3\")\n",
    "                break\n",
    "            # compile the model\n",
    "            model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                       optimizer=tf.optimizers.Adam(lr=lr),\n",
    "                        metrics=['categorical_accuracy',\n",
    "                               MulticlassAUC(pos_label=0, name=\"AUC_Normal\"),\n",
    "                               MulticlassAUC(pos_label=1, name=\"AUC_NCP\"),\n",
    "                               MulticlassAUC(pos_label=2, name=\"AUC_CP\")\n",
    "                        ])\n",
    "\n",
    "\n",
    "            print('\\n**************************************************\\n')\n",
    "            print('Fold:', i+1)\n",
    "            print('\\n**************************************************\\n')\n",
    "\n",
    "            # Define data loaders.\n",
    "            train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "            validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val)) \n",
    "            test_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "            # Augment the on the fly during training.\n",
    "            train_dataset = (\n",
    "                train_loader.shuffle(len(x_train))\n",
    "                .map(train_preprocessing, num_parallel_calls=batch_size)\n",
    "                    .batch(batch_size)\n",
    "                    .prefetch(r_batch_size)\n",
    "            )\n",
    "            # Only rescale.\n",
    "            validation_dataset = (\n",
    "                validation_loader.map(test_and_validation_preprocessing, num_parallel_calls=batch_size)\n",
    "                    .batch(batch_size)\n",
    "                    .prefetch(r_batch_size)\n",
    "            )\n",
    "            # Only rescale.\n",
    "            test_dataset = (\n",
    "                test_loader.map(test_and_validation_preprocessing, num_parallel_calls=batch_size)\n",
    "                    .batch(batch_size)\n",
    "                    .prefetch(r_batch_size)\n",
    "            )\n",
    "\n",
    "            early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", min_delta=0.05, patience=15)\n",
    "            \n",
    "            log_cb=tf.keras.callbacks.TensorBoard(log_dir = \"./tb_log_dir\")\n",
    "\n",
    "            checkpoint_filepath_1 = models_path+'best_model.h5'\n",
    "            best_model_checkpoint_acc_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath_1,\n",
    "                save_weights_only=True,\n",
    "                monitor='val_categorical_accuracy',\n",
    "                mode='max',\n",
    "                save_best_only=True\n",
    "            )\n",
    "\n",
    "            checkpoint_filepath_2 = models_path+'best_model_loss.h5'\n",
    "            best_model_checkpoint_loss_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath_2,\n",
    "                save_weights_only=True,\n",
    "                monitor='val_loss',\n",
    "                mode='max',\n",
    "                save_best_only=True\n",
    "            )\n",
    "\n",
    "            checkpoint_models_path = models_path+'{epoch:02d}-{categorical_accuracy:.2f}-{val_categorical_accuracy:.2f}.h5'\n",
    "            all_models_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_models_path,\n",
    "                save_weights_only=True\n",
    "            )\n",
    "\n",
    "            history=model.fit(\n",
    "                train_dataset,\n",
    "                validation_data=validation_dataset,\n",
    "                epochs=epochs,\n",
    "                #shuffle=True,\n",
    "                verbose=2,\n",
    "                callbacks=[best_model_checkpoint_acc_cb,\n",
    "                            best_model_checkpoint_loss_cb,\n",
    "                            log_cb]\n",
    "            )\n",
    "\n",
    "            # Save model last epoch\n",
    "            model.save_weights(models_path+'last_epoch.h5')\n",
    "\n",
    "            #print('\\nEvaluating TRAINING SET (last epoch) ')\n",
    "            #model.evaluate(train_dataset, verbose=1)\n",
    "\n",
    "            #print('\\n**** Confusion Matrix ****')\n",
    "            #y_pred = model.predict(train_dataset)\n",
    "            #cm = confusion_matrix(y_train, y_pred)\n",
    "            #print(cm)\n",
    "\n",
    "\n",
    "            print('\\nEvaluating VALIDATION SET (last epoch) ')\n",
    "            model.evaluate(validation_dataset, verbose=1)\n",
    "\n",
    "            print('\\n**** Confusion Matrix ****')\n",
    "            y_pred = model.predict(validation_dataset)\n",
    "            cm = confusion_matrix(y_val, y_pred)\n",
    "            print(cm)\n",
    "\n",
    "            print('\\nEvaluating TEST SET (last epoch)')\n",
    "\n",
    "            score_test_lastepoch = model.evaluate(test_dataset, verbose=1)\n",
    "            scores_test_lastepoch['loss'][idx]=score_test_lastepoch[0]\n",
    "            scores_test_lastepoch['categorical_accuracy'][idx]=score_test_lastepoch[1]\n",
    "\n",
    "            print('Test loss:', score_test_lastepoch[0])\n",
    "            print('Test accuracy:', score_test_lastepoch[1])\n",
    "            print('\\n**** Confusion Matrix ****')\n",
    "\n",
    "            y_pred = model.predict(test_dataset)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            print(cm)\n",
    "\n",
    "            print('\\nEvaluating TEST SET (best model)') \n",
    "            model.load_weights(checkpoint_filepath_1) \n",
    "            score_acc = model.evaluate(test_dataset, verbose=1)\n",
    "            scores_acc['loss'][idx]=score_acc[0]\n",
    "            scores_acc['categorical_accuracy'][idx]=score_acc[1]\n",
    "\n",
    "            print('Test loss:', score_acc[0])\n",
    "            print('Test accuracy:', score_acc[1])\n",
    "            print('\\n**** Confusion Matrix ****')\n",
    "            y_pred = model.predict(test_dataset)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            print(cm)\n",
    "\n",
    "            idx += 1\n",
    "            \n",
    "\n",
    "# start training for all folds\n",
    "# replace data and models path with your directory\n",
    "\n",
    "\n",
    "ct_scan_depth = 25; ct_scan_width = 256; ct_scan_height = 256;\n",
    "dropout_prob=0.0\n",
    "cnn='iv1'\n",
    "data_path = \"/home/pwrai/notebook/clean_cc_ccii_folds/\"+str(ct_scan_depth)+\"/\" \n",
    "\n",
    "if cnn=='iv1':\n",
    "    models_path = \"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v1/drop_\"+str(dropout_prob).replace('.','')+\"/fold_\"+str(fold)+\"/\n",
    "elif cnn=='iv3':\n",
    "    models_path = \"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v3/drop_\"+str(dropout_prob).replace('.','')+\"/fold_\"+str(fold)+\"/\n",
    "\n",
    "\n",
    "\n",
    "training(cnn, ct_scan_width, ct_scan_height, ct_scan_depth, data_path, models_path, dropout_prob=dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# \n",
    "# Soft-Voting Ensemble model\n",
    "#\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from numpy import tensordot\n",
    "from sklearn.metrics import accuracy_score\n",
    "from models.InceptionV1_3D import Inception_Inflated3d\n",
    "from models.InceptionV3_3D import Inception_v3_Inflated3d\n",
    "from utils.confusion_matrix import cm as confusion_matrix \n",
    "\n",
    "\n",
    "\n",
    "def ensemble_predictions(members, weights, testX):\n",
    "    # make predictions\n",
    "    yhats = [model.predict(testX) for model in members]\n",
    "    yhats = np.array(yhats)\n",
    "    # weighted sum across ensemble members\n",
    "    summed = tensordot(yhats, weights, axes=((0),(0)))\n",
    "    # argmax across classes\n",
    "    result = np.argmax(summed, axis=1)\n",
    "    return result, summed \n",
    "\n",
    "\n",
    "\n",
    "# CNN architecture: use 'iv1' for Inception-V1 or 'iv3' for Inception-V3\n",
    "cnn='iv1'\n",
    "\n",
    "# replace with the FOLD that should be used to assess the ensemble model\n",
    "fold=1\n",
    "\n",
    "# parameters related to the CT scan sizes\n",
    "ct_scan_depth = 25\n",
    "ct_scan_width = 256\n",
    "ct_scan_height = 256\n",
    "num_channels = 1\n",
    "\n",
    "# load test set\n",
    "# replace with your directory\n",
    "data_path = \"/home/pwrai/notebook/clean_cc_ccii_folds/\"+str(ct_scan_depth)+\"/fold_\"+fold+\"/\"\n",
    "x_test = np.load(data_path+'x_test.npy')\n",
    "y_test = np.load(data_path+'y_test.npy')\n",
    "\n",
    "x_test = np.swapaxes( x_test, 1, -1); x_test = np.swapaxes( x_test, -2, -1)\n",
    "\n",
    "test_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "batch_size = 16 # global batch size\n",
    "r_batch_size = 16 # replica batch size\n",
    "test_dataset = (\n",
    "                test_loader.map(test_and_validation_preprocessing, num_parallel_calls=batch_size)\n",
    "                   .batch(batch_size)\n",
    "                    .prefetch(r_batch_size)\n",
    "                )\n",
    "\n",
    "# load the individual models. For a given fold five models will be loaded\n",
    "# replace the path of the models with your paths\n",
    "# the loaded models (built for different dropout values) must refer to the same fold\n",
    "\n",
    "model1=None\n",
    "model2=None\n",
    "model3=None\n",
    "model4=None\n",
    "model5=None\n",
    "\n",
    "if cnn=='iv1':\n",
    "    model1 = Inception_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.0, classes=3)\n",
    "    model1.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v1/drop_03/fold_\"+str(fold)+\"/best_model.h5\")\n",
    "    model2= Inception_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.3, classes=3)\n",
    "    model2.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v1/drop_03/fold_\"+str(fold)+\"/best_model.h5\")\n",
    "\n",
    "    model3 = Inception_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.4, classes=3)\n",
    "    model3.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v1/drop_04/fold_\"+str(fold)+\"/best_model.h5\")       \n",
    "\n",
    "    model4 = Inception_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.5, classes=3)\n",
    "    model4.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v1/drop_05/fold_\"+str(fold)+\"/best_model.h5\")\n",
    "\n",
    "\n",
    "    model5 = Inception_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.6, classes=3)\n",
    "    model5.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v1/drop_06/fold_\"+str(fold)+\"/best_model.h5\")\n",
    "\n",
    "elif cnn=='iv3':\n",
    "    model1 = Inception_v3_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.0, classes=3)\n",
    "    model1.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v3/drop_00/fold_\"+str(fold)+\"/best_model.h5\")\n",
    "\n",
    "    model2= Inception_v3_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.3, classes=3)\n",
    "    model2.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v3/drop_03/fold_\"+str(fold)+\"/best_model.h5\")\n",
    "\n",
    "    model3 = Inception_v3_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.4, classes=3)\n",
    "    model3.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v3/drop_04/fold_\"+str(fold)+\"/best_model.h5\")       \n",
    "\n",
    "    model4 = Inception_v3_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.5, classes=3)\n",
    "    model4.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v3/drop_05/fold_\"+str(fold)+\"/best_model.h5\")\n",
    "\n",
    "\n",
    "    model5 = Inception_v3_Inflated3d(include_top=False, \n",
    "                                input_shape=(ct_scan_depth, img_size, img_size, num_channels),\n",
    "                                dropout_prob=0.6, classes=3)\n",
    "    model5.load_weights(\"/home/pwrai/notebook/my_models/\"+str(ct_scan_depth)+\"/Inception_v3/drop_06/fold_\"+str(fold)+\"/best_model.h5\")\n",
    "    \n",
    "if model1!=None:\n",
    "    members = [model1, model2, model3, model4, model5]\n",
    "    weights = [1/5, 1/5, 1/5, 1/5, 1/5] \n",
    "    results, y_scores = ensemble_predictions(members, weights, test_dataset)\n",
    "\n",
    "\n",
    "    # Assess results and print the confusion matrix\n",
    "    y_pred=[]\n",
    "    for i in results:\n",
    "        if i==0: y_pred.append([1, 0 , 0])\n",
    "        elif i==1: y_pred.append([0, 1, 0])\n",
    "        elif i==2: y_pred.append([0, 0, 1])\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
